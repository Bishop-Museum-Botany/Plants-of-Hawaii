---
title: "POH Merge Data from Multiple Herbaria Pipeline"
author: "Kelsey Brock"
date: "12/9/2020"
output: html_document
---
The Script below performs the following for each of BISH, PTBG, US and GBIF herbarium data:
1) Merges occurrence data from each herbarium with the POH Taxon Table
2) Perform cleanup on data:
  -reprojecting lat lons, putting them in the right columns
  - joining certain fields, etc)
3) Renames columns according to POH data schema (DarwinCore names) and selects rows that we want
Then:
4) Collates herbarium data into a single file
5) Removes obvious duplicates, keeping BISH data as priority
6) Standardizes the spelling of island names
7) Removes bad latlon points that fall in the ocean
8) Standardizes Date Format
9) Assigns a cultivated, naturalized or unknown status


TO-DO list:
1) tricky coordinates have not yet been coerced into decimal lat lon, and these have been coverted to NA
2) Elevation has not yet been converted to metric units (they are currently in ft or m)
3) I have so far only matched GPS points with main islands
5) The dataset likely contains multiple duplicates. It would be great to clean recordedBy and collector numbers so we can find duplicates easier and also find duplicates with different IDs
6) PRIORITY! Reconcile discarded occurrences with POH taxon list. Some of these have been addressed, but some more time is needed to comb through the outcast lists. We're still discarding multiple rows of source data, but some of this may be due to messy nonsense in the source dataset rather than a  taxon name.
7) there appears to be some species that haven't been assigned an accepted name 
8) How are we going to deal with occurrence UUID and version updates? We want UUIDs for incorporated occurrences to be static, so we need to code it so that only new occurrence records get a new ID.
9) How do we assign a location ID?
10) several dates appear to be blank - need to make sure these are truly blank in the native source and that I've not tried to coerce them into a format that doesn't fit.
11) we should replace ridiculous dates with NAs; these appear to be embedded in the source data - not a scripting problem.





```{r, }
require(knitr)
```
```{r}
#get the needed packages
#get the needed packages
if(!require("pacman")){
	install.packages("pacman")
	library(pacman)}
p_load("dplyr",  "ggplot2", "taxize", "sp", "sf", "proj4", "data.table", "stringr", "flora", "DataCombine", "parzer", "stringi", "scrubr", "ids", "lubridate", "hablar", "data.table")
```
## These are the fields we ultimately want in the final data set
These are DarwinCore column names that are currently in the POH schema
```{r}

Taxonfields <- c( "taxonID", "acceptedNameUsageID", "IPNIID", "parentNameUsageID", "scientificName", "scientificNameAuthorship", "namePublishedIn", "originalNameUsage", "taxonRank", "kingdom", "phylum", "class", "order", "family", "genus", "subgenus", "specificEpithet", "vernacularName", "taxonRemarks")

Locationfields <- c("locationID", "higherGeographyID", "locationType", "continent", "waterbody", "islandGroup", "island", "country", "countrycode", "stateProvince", "county", "municipality", "locality", "minimumElevationInMeters", "maximumElevationInMeters", "decimalLatitude", "decimalLongitude", "geodeticDatum", "coordinateUncertaintyInMeters", "footprintWKT", "footprintSRS", "locationRemarks" )

Occurrencefields <- c("occurrenceID", "taxonID", "locationID", "basisOfRecord", "catalogNumber", "recordNumber", "recordedBy", "individualCount", "organismQuantity", "organismQuantityType", "identifiedby", "identificationVerification", "sex", "lifeStage", "reproductiveCondition", "behavior", "establishmentMeans", "occurrenceStatus", "preparations", "disposition", "associatedMedia", "associatedReferences", "associatedTaxa", "otherCatalogNumbers", "occurrenceRemarks", "fieldNumber", "eventDate", "eventTime", "habitat", "samplingProtocol", "fieldNotes", "watershedCount", "isCultivated", "source", "sourceIdentifier", "sourceURL")

Allfields <- unique(c(Taxonfields, Locationfields, Occurrencefields))
```

## Read in the Data Sets
IMPORTANT!! Before reading in csvs, make sure excel hasn't converted the date format! go in and make sure the date cells are formatted as YYYY-mm-dd
```{r}
#Taxon Table for first merging

POH_taxon_2 <- read.csv("POH_TAXA_12_17_2020.csv", header=T, sep=',', stringsAsFactors=F) %>% dplyr::select(taxonID, acceptedNameUsageID, scientificName, scientificNameAuthorship, kingdom,	phylum,	class,	order,	family,	genus, vernacularName, BISH_TaxonID)
POH_taxon_2 <- subset(POH_taxon_2, POH_taxon_2$acceptedNameUsageID != "")
POH_taxon_2 <- subset(POH_taxon_2, !is.na(POH_taxon_2$acceptedNameUsageID))

POH_taxon_1 <-  POH_taxon_2 %>% dplyr::select(acceptedNameUsageID, scientificName, BISH_TaxonID)
POH_taxon_2 <- subset(POH_taxon_2, POH_taxon_2$acceptedNameUsageID == POH_taxon_2$taxonID)
```
```{r}
#Herbarium Data                                                                                                         
BISH <- read.csv("BISH_Hawaii_Specimens_1_18_2021 - Copy.csv", header=T, sep=',', stringsAsFactors=F) 
PTBG <- read.csv("NTBG_HerbariumSearchExport_20201221.csv", header=T, sep=',', fill=TRUE ,quote = "\"" ,na.strings=c("NA","?"),dec=".",comment.char="", stringsAsFactors=F)
  PTBG <- subset(PTBG, PTBG$ISLAND_GROUP == "HAWAIIAN ISLANDS")
US <- read.csv("nmnhsearch-20201210005846_dateconvert.csv", header=T, sep=',', stringsAsFactors=F)
GBIF <- read.csv("occurrence.csv", header=T, sep=',', stringsAsFactors=F) %>% dplyr::rename(TaxonomicName = scientificName) %>% dplyr::select(-c(acceptedNameUsageID,	taxonID, kingdom,	phylum,	class,	order,	family,	genus, vernacularName))
  ## subset to remove human occurrences (we'll deal with those later)
  GBIF_pres_spec <- subset(GBIF, GBIF$basisOfRecord == "PRESERVED_SPECIMEN")
idigbio <- read.csv("iDigBio.csv", header=T, sep=',', stringsAsFactors=F)
  idig_from_raw <- read.csv("idigbio_raw.csv", header=T, sep=',', stringsAsFactors=F)%>% dplyr::select(dwc.associatedOccurrences, aec.associatedTaxa, dwc.habitat, dwc.island, dwc.islandGroup, dwc.institutionCode )
  idigbio <- cbind(idig_from_raw, idigbio)
```
```{r}
#This polygon is only for the main hawaiian islands - we should build another that includes the NW islands
islandpolys <- st_read("Coastline.shp")
```

###### Where to get updates of these data sets:
BISH <- download from BISH Specimen Database, joined with Tim's taxon table to get ID number
PTBG <- http://lawai.ntbg.org/ you need an account to login 
US <- https://collections.nmnh.si.edu/search/botany/; Category "flowering plants and ferns",State = "Hawaii"; only downloads 10000 at a time (do multiple dowloads based on time periods)
GBIF <- from GBIF.org "POLYGON((-161.0376 17.79054,-153.91846 17.79054,-153.91846 23.70489,-161.0376 23.70489,-161.0376 17.79054))" (main hawaiian islands); has geospatial issue = FALSE, Occurrence Status - Present, Scientific Name = Tracheopyta, darwin core archive format. comes in .zip file, download "occurrence.txt", convert to .csv in Excel.
POH_taxon <- Maintained by Tim
islandpolys <- https://geoportal.hawaii.gov/datasets/045b1d5147634e2380566668e04094c6_3

Make sure Nulls are changed to NAs

How many occurrence records are we combining (including duplicates?)
```{r}
nrow(BISH) + nrow(PTBG) + nrow(US) + nrow(GBIF_pres_spec) + nrow(idigbio)
```
```{r}
nrow(BISH)
```
```{r}
nrow(PTBG)
```
```{r}
nrow(US)
```
```{r}
nrow(GBIF_pres_spec)
```
```{r}
nrow(idigbio)
```
```{r}
BISH
```

# BISH Herbarium Data
## 1. BISH- Merge with POH table

Merging BISH database output with taxon names and ID #s

How many species won't merge (ie. have no scientific name associated with a BISH_taxonID?)?

```{r}
temp <- merge(BISH, POH_taxon_1, by.x = "TaxonNameID", by.y = "BISH_TaxonID", all.x = TRUE, all.y = FALSE)
temp <- subset(temp, is.na(temp$scientificName))
occ <- nrow(temp)
tax <- length(unique(temp$TaxonNameID))
print(paste0("lost ", occ , " occurrences represented by ", tax, " BISH taxon IDs"))
write.csv(temp, file = "BISHIDs_Not_in_POH_table_12102020.csv", row.names = FALSE)
```
```{r}
BISH<- merge(BISH, POH_taxon_1, by.x = "TaxonNameID", by.y = "BISH_TaxonID", all.x = FALSE, all.y = FALSE)
```

Second merge to assign an accepted scientific name
```{r}
BISH <- merge(POH_taxon_2, BISH, by = "acceptedNameUsageID", all.x = FALSE, all.y = TRUE) %>% dplyr::rename(scientificName = scientificName.x)
```


## 2. BISH- Data Cleanup
deal with messy GPS coordinate data of different types
```{r include=FALSE}
BISH_nocoords <- subset(BISH, is.na(BISH$LatDeg))
BISH_coords <- subset(BISH, !is.na(BISH$LatDeg))

BISH_declat <- subset(BISH_coords, is.na(BISH_coords$LatMin))
BISH_minsec <- subset(BISH_coords, !is.na(BISH_coords$LatMin))
BISH_UTMs_Northing <-  grepl.sub(data = BISH_nocoords, pattern = "Northing", Var = "COMMENT")
BISH_UTMs_UTM <-  grepl.sub(data = BISH_nocoords, pattern = "UTM", Var = "COMMENT")

# assign a blank - noo coords here
BISH_nocoords$decimalLatitude = ""
BISH_nocoords$decimalLongitude = ""

# no conversion needed for these
BISH_declat$decimalLatitude = BISH_declat$LatDeg
BISH_declat$decimalLongitude = BISH_declat$LongDeg

# converting DMS to decimal degree format
BISH_minsec$decimalLatitude_temp = paste0(BISH_minsec$LatDeg, " ", BISH_minsec$LatMin, " ", BISH_minsec$LatSec)
BISH_minsec$decimalLongitude_temp = paste0(BISH_minsec$LongDeg, " ", BISH_minsec$LongMin, " ", BISH_minsec$LongSec)
BISH_minsec$decimalLatitude_temp = gsub("NA", "0", BISH_minsec$decimalLatitude_temp)
BISH_minsec$decimalLongitude_temp = gsub("NA", "0", BISH_minsec$decimalLongitude_temp)


BISH_minsec$decimalLatitude = parzer::parse_lat(BISH_minsec$decimalLatitude_temp)
BISH_minsec$decimalLongitude = parzer::parse_lon(BISH_minsec$decimalLongitude_temp)
```

Extracting UTMs from comments section -this needs some more work, but it extracts most of them
```{r}
#extracting UTMS from comments section for things that look like northings
Northing_starts_with <- c(".{0,33}21.{0,7}", ".{0,33}22.{0,7}", ".{0,33}23.{0,7}", ".{0,33}24.{0,7}")
tempcoord <- stringr::str_extract(BISH_UTMs_UTM$COMMENT, Northing_starts_with)
# get rid of messing alph numerics
tempcoord <- gsub("4Q", "", tempcoord)
tempcoord <- gsub("4 Q", "", tempcoord)
tempcoord <- gsub("04Q", "", tempcoord)
tempcoord <- gsub("04 Q", "", tempcoord)
tempcoord <- gsub("zone 4", "", tempcoord)
tempcoord <- gsub("NAD 83", "", tempcoord)
tempcoord <- gsub("NAD83", "", tempcoord)
tempcoord <- gsub("Zone 4", "", tempcoord)

# remove letters and punctuation
regexp1 <- "[[:alpha:]]+"
regexp2 <- "[[:punct:][:blank:]]+"
tempcoord <- gsub(regexp1, "", (stringr::str_extract(tempcoord, Northing_starts_with)))
tempcoord <- gsub(regexp2, "", tempcoord)
#split string into northing and easting
tempcoorddf <- as.data.frame(tempcoord)
tempcoorddf <- tempcoorddf %>% tidyr::separate(tempcoord, into = c("easting", "northing"), sep = -7, convert = TRUE)
tempcoorddf$flagged <- if_else(tempcoorddf$northing >=2000000 & tempcoorddf$northing <=2500000, "Good Coord", "Bad Coord", missing = NULL)
BISH_UTMs_UTM <- cbind(BISH_UTMs_UTM, tempcoorddf)
```

```{r}
#extracting UTMS from comments section for things that look like northings
Northing_find <- c(".{0,0}Northing:.{0,12}")
Easting_find <- c(".{0,0}Easting:.{0,12}")
easting <- stringr::str_extract(BISH_UTMs_Northing$COMMENT, Easting_find)
northing <- stringr::str_extract(BISH_UTMs_Northing$COMMENT, Northing_find)

 #remove letters and punctuation and trim number
regexp1 <- "[[:alpha:]]+"
regexp2 <- "[[:punct:][:blank:]]+"
easting <- gsub(regexp1, "", easting)
easting <- gsub(regexp2, "", easting)
northing <- gsub(regexp1, "", northing)
northing <- gsub(regexp2, "", northing)
northing <- substr(northing,1,7)
easting <- substr(easting,1,6)

#combine dataframe

BISH_UTMs_Northing <- cbind(BISH_UTMs_Northing, easting, northing)
BISH_UTMs_Northing$flagged <- if_else(BISH_UTMs_Northing$northing >=2000000 & BISH_UTMs_Northing$northing <=2500000,  "Bad Coord", "Good Coord",missing = NULL)

BISH_UTMs <- rbind(BISH_UTMs_Northing, BISH_UTMs_UTM)
```

Reprojecting UTMs to lat lons
```{r}
BISH_UTMs_BI <- subset(BISH_UTMs, ISCO == "Hawaii")
BISH_UTMs_west <- subset(BISH_UTMs, ISCO != "Hawaii")


proj4stringBI="+proj=utm +zone=5 +datum=NAD83"
proj4stringwest="+proj=utm +zone=4 +datum=NAD83"


BI<- BISH_UTMs_BI %>% 
  dplyr::select(easting, northing) %>%
  project(proj4stringBI, inverse=TRUE)

BIlatlon <- data.frame(lat=BI$y, lon=BI$x)


west<- BISH_UTMs_west %>% 
  dplyr::select(easting, northing) %>%
  project(proj4stringwest, inverse=TRUE)

westlatlon <- data.frame(lat=west$y, lon=west$x)


BISH_UTMs_BI <-BIlatlon %>% 
  dplyr::rename(decimalLatitude = lat, decimalLongitude = lon) %>%
  cbind(BISH_UTMs_BI)
BISH_UTMs_west <- westlatlon %>% dplyr::rename(decimalLatitude = lat, decimalLongitude = lon) %>%
  cbind(BISH_UTMs_west)
                          

BISH_UTMs <- rbind(BISH_UTMs_BI, BISH_UTMs_west)

```
```{r}

```


## 3. BISH- Standardize column names and select the ones we want
```{r}
#extracting out the column names that we want
# first renaming everything to Darwincore
#then extractig the fields we want
BISH_nocoords <- BISH_nocoords %>% 
  dplyr::rename(islandGroup = DATASET, recordedBy = COLLECTOR, recordNumber = COLLNUMBER, locality = LOCALITY, eventDate = COLLDATE, habitat = HABITAT, stateProvince = STATEPROV, island = ISCO, minimumElevationInMeters = VerbatimElevation, isCultivated = CULTIVATED, cultivar = CVAR,  occurrenceRemarks = PLDESCR, country = COUNTRY, fieldNotes = COMMENT, catalogNumber = IDNUMBER, otherCatalogNumbers = TaxonNameID, identifiedby = DETERMINER, identificationVerification = VERIFIEDBY) %>% 
  dplyr::select(dplyr::any_of(Allfields))

BISH_declat <- BISH_declat %>% 
  dplyr::rename(islandGroup = DATASET, recordedBy = COLLECTOR, recordNumber = COLLNUMBER, locality = LOCALITY, eventDate = COLLDATE, habitat = HABITAT, stateProvince = STATEPROV, island = ISCO, minimumElevationInMeters = VerbatimElevation, isCultivated = CULTIVATED, cultivar = CVAR,  occurrenceRemarks = PLDESCR, country = COUNTRY, fieldNotes = COMMENT, catalogNumber = IDNUMBER, otherCatalogNumbers = TaxonNameID, identifiedby = DETERMINER, identificationVerification = VERIFIEDBY) %>% 
  dplyr::select(dplyr::any_of(Allfields))

BISH_minsec <- BISH_minsec %>% 
  dplyr::rename(islandGroup = DATASET, recordedBy = COLLECTOR, recordNumber = COLLNUMBER, locality = LOCALITY, eventDate = COLLDATE, habitat = HABITAT, stateProvince = STATEPROV, island = ISCO, minimumElevationInMeters = VerbatimElevation, isCultivated = CULTIVATED, cultivar = CVAR,  occurrenceRemarks = PLDESCR, country = COUNTRY, fieldNotes = COMMENT, catalogNumber = IDNUMBER, otherCatalogNumbers = TaxonNameID, identifiedby = DETERMINER, identificationVerification = VERIFIEDBY) %>% 
  dplyr::select(dplyr::any_of(Allfields))

BISH_UTMs <- BISH_UTMs %>% 
  dplyr::rename(islandGroup = DATASET, recordedBy = COLLECTOR, recordNumber = COLLNUMBER, locality = LOCALITY, eventDate = COLLDATE, habitat = HABITAT, stateProvince = STATEPROV, island = ISCO, minimumElevationInMeters = VerbatimElevation, isCultivated = CULTIVATED, cultivar = CVAR,  occurrenceRemarks = PLDESCR, country = COUNTRY, fieldNotes = COMMENT, catalogNumber = IDNUMBER, otherCatalogNumbers = TaxonNameID, identifiedby = DETERMINER, identificationVerification = VERIFIEDBY) %>% 
  dplyr::select(dplyr::any_of(Allfields))

BISH <- rbind(BISH_nocoords, BISH_declat, BISH_minsec, BISH_UTMs)
nrow(BISH)
```


# PTBG Herbarium Data
## 1. PTBG- Merge with POH table

making a single TaxonName field so we can merge



```{r}
PTBG <- subset(PTBG, PTBG$species != "")
PTBG <- subset(PTBG, PTBG$family != "")

PTBG_spp <- subset(PTBG, PTBG$subspecies == "" & PTBG$variety == "")
PTBG_subsp <- subset(PTBG, PTBG$subspecies != "" & PTBG$variety == "")
PTBG_vars <- subset(PTBG, subspecies == "" & PTBG$variety != "")

PTBG_spp$TaxonName <- paste0(PTBG_spp$genus, " ", PTBG_spp$species)
PTBG_subsp$TaxonName <- paste0(PTBG_subsp$genus, " ", PTBG_subsp$species, " subsp. ", PTBG_subsp$subspecies)
PTBG_vars$TaxonName <- paste0(PTBG_vars$genus, " ", PTBG_vars$species, " var. ", PTBG_vars$variety)

PTBG <- rbind(PTBG_spp, PTBG_subsp,  PTBG_vars)
```

```{r}
temp <- merge(POH_taxon_1, PTBG, by.y = "TaxonName", by.x = "scientificName", all.x = FALSE, all.y = TRUE)
temp <- subset(temp, is.na(temp$acceptedNameUsageID))
occ <- nrow(temp)
tax <- length(unique(temp$scientificName))
print(paste0("lost ", occ , " occurrences represented by ", tax, " unique values in the taxa names field"))
```
```{r}
#get rid of extraneous columns
PTBG <- PTBG %>% dplyr::select(-c(genus, family))
PTBG<- merge(POH_taxon_1, PTBG, by.y = "TaxonName", by.x = "scientificName", all.x = FALSE, all.y = FALSE)
# but still want to export mismatches
write.csv(temp, file = "PTBGtaxa_Not_in_POH_table_12102020.csv", row.names = FALSE)
```

Second merge to assign an accepted scientific name
```{r}
PTBG <- merge(POH_taxon_2, PTBG, by = "acceptedNameUsageID", all.x = FALSE, all.y = TRUE) %>% dplyr::rename(scientificName = scientificName.x)
```



## 2. PTBG- Data Cleanup
Creating a single associated species column
```{r}
#making a better associated spp column
PTBG$associatedTaxa = paste0(PTBG$ASSCSPP, ", ", PTBG$THREATS)
```


## 3. PTBG- Standardize column names and select the ones we want
```{r}
#rename and select columns
# rename new_name = old_name
PTBG <- PTBG %>% 
  dplyr::rename( catalogNumber = barcode, eventDate = COLDATE, recordNumber = COLID, recordedBy = COLNAME, fieldNotes = comments, country = COUNTRY, county = COUNTY, isCultivated = CULTIVATED, municipality = DISTRICT, minimumElevationInMeters = ELEVM, establishmentMeans = FREQUENCY, habitat = HABITAT, island = ISLAND, islandGroup = ISLAND_GROUP, decimalLatitude = LATDEC, decimalLongitude = LONGDEC, locality = LOCALITY, occurrenceRemarks = PLANTDESC, otherCatalogNumbers = SPECID, stateProvince=STATE) %>% 
  dplyr::select(dplyr::any_of(Allfields))

```
```{r}
nrow(PTBG)
```

# GBIF Herbarium Data
## 1. GBIF- Merge with POH table

Get rid of authornames that are embedded in the taxon name

```{r}
GBIF_pres_spec$scientificName_clean <- unlist(lapply(GBIF_pres_spec$TaxonomicName, remove.authors))
```
```{r}
temp <- merge(POH_taxon_1, GBIF_pres_spec,  by.x = "scientificName", by.y = "scientificName_clean", all.x = FALSE, all.y = TRUE)
temp <- subset(temp, is.na(temp$acceptedNameUsageID))
occ <- nrow(temp)
tax <- length(unique(temp$scientificName))
# but still want to export mismatches
write.csv(temp, file = "GBIFtaxa_Not_in_POH_table_12102020.csv", row.names = FALSE)
print(paste0("lost ", occ , " occurrences represented by ", tax, " unique values in the taxa names field"))
```
```{r}
GBIF_pres_spec<- merge(POH_taxon_1, GBIF_pres_spec,  by.x = "scientificName", by.y = "scientificName_clean", all.x = FALSE, all.y = FALSE)
```

Second merge to assign an accepted scientific name
```{r}
GBIF_pres_spec <- merge(POH_taxon_2, GBIF_pres_spec, by = "acceptedNameUsageID", all.x = FALSE, all.y = TRUE) %>% dplyr::rename(scientificName = scientificName.x, Year = year)
```


## 2. GBIF- Data Cleanup
none

## 3. GBIF- Standardize column names and select the ones we want
```{r}
# new_name = old_name
GBIF_pres_spec <- GBIF_pres_spec %>% 
  dplyr::rename(publisher_temp = publisher, source_temp = source) %>% 
  dplyr::rename(source = publisher_temp) %>% 
  dplyr::select(dplyr::any_of(Allfields))
```
```{r}
nrow(GBIF_pres_spec)
```
# US Herbarium Data
## 1. US- Merge with POH table

```{r}
#need to split string to get rid of "filed as" portion of taxon name
US$TaxonName <- str_extract(US$Taxonomic.Name..Filed.As...Identified.By...Identification.Date., "[^:]+")
#need to remove author
US$TaxonName <- unlist(lapply(US$TaxonName, remove.authors))

US$TaxonName = gsub("f.", "", US$TaxonName)
US$TaxonName = gsub("sp.", "", US$TaxonName)
```
```{r}
temp <- merge(POH_taxon_1, US,  by.x = "scientificName", by.y = "TaxonName", all.x = FALSE, all.y = TRUE)
temp <- subset(temp, is.na(temp$acceptedNameUsageID))
occ <- nrow(temp)
tax <- length(unique(temp$scientificName))
print(paste0("lost ", occ , " occurrences represented by ", tax, " unique values in the taxa names field"))
```
```{r}
US<- merge(POH_taxon_1, US,  by.x = "scientificName", by.y = "TaxonName", all.x = FALSE, all.y = FALSE)
# but still want to export mismatches
write.csv(temp, file = "UStaxa_Not_in_POH_table_12102020.csv", row.names = FALSE)
```

```{r}
US <- merge(POH_taxon_2, US, by = "acceptedNameUsageID", all.x = FALSE, all.y = TRUE) %>% dplyr::rename(scientificName = scientificName.x)
```

```{r}
nrow(US)
```
## 2. US- Data Cleanup
 very little lat lon data in here

## 3. US- Standardize column names and select the ones we want
```{r}
# new_name = old_name
US <- US %>% 
  dplyr::rename(islandGroup = Archipelago, catalogNumber = Barcode, otherCatalogNumbers=Catalog.Number, decimalLatitude = Centroid.Latitude, decimalLongitude = Centroid.Longitude, recordNumber = Collection.Number, fieldNotes = Collection.Remarks, recordedBy = Collector.s., country = Country, isCultivated = Cultivated, eventDate = Date.Collected, county = District.County, minimumElevationInMeters =Elevation..m., island =Island.Name, habitat = Microhabitat.Description, locality=Precise.Locality,  stateProvince = Province.State, taxonRemarks = Taxonomy.Remarks) %>% dplyr::select(dplyr::any_of(Allfields))
```


# iDigBio Herbarium Data

## 1. iDigBio- Merge with POH table

First, need to capitalize the genus part of the name
```{r}
idigbio$dwc.scientificName_clean <- paste(toupper(substr(idigbio$dwc.scientificName, 1, 1)), substr(idigbio$dwc.scientificName, 2, nchar(idigbio$dwc.scientificName)), sep="")
```
Let's get rid of the formas
```{r}
idigbio$dwc.scientificName_clean <- gsub("f\\..*", "", idigbio$dwc.scientificName_clean)
```

Get rid of authornames that are embedded in the taxon name
```{r}
idigbio$dwc.scientificName_clean <- unlist(lapply(idigbio$dwc.scientificName_clean, remove.authors))
```

OkAY, let's try to merge with POH taxon table
```{r}
temp <- merge(POH_taxon_1, idigbio,  by.x = "scientificName", by.y = "dwc.scientificName_clean", all.x = FALSE, all.y = TRUE)
temp <- subset(temp, is.na(temp$acceptedNameUsageID))
occ <- nrow(temp)
tax <- length(unique(temp$scientificName))
# but still want to export mismatches
write.csv(temp, file = "idigbiotaxa_Not_in_POH_table_12102020.csv", row.names = FALSE)
print(paste0("lost ", occ , " occurrences represented by ", tax, " unique values in the taxa names field"))
```

```{r}
idigbio<- merge(POH_taxon_1, idigbio,  by.x = "scientificName", by.y = "dwc.scientificName_clean", all.x = FALSE, all.y = FALSE)
```

Second merge to assign an accepted scientific name
```{r}
idigbio <- merge(POH_taxon_2, idigbio, by = "acceptedNameUsageID", all.x = FALSE, all.y = TRUE) %>% dplyr::rename(scientificName = scientificName.x)
```
```{r}
idigbio <- subset(idigbio, !is.na(idigbio$scientificName))
```
```{r}
nrow(idigbio)
```

## 2. idigbio- Data Cleanup
have to split lat and lon into different column, clean, and then rebind

```{r}
latlon <- str_split_fixed(idigbio$idigbio.geoPoint, ",", 2)

regexp_alpha <- "[[:alpha:]]+" 
regexp_blank <- "[[:blank:]]+"
latlon <- gsub(regexp_alpha, "", latlon)
latlon<- gsub(regexp_blank, "", latlon)
latlon<- gsub("*.:", "", latlon)
latlon<- gsub("[{]", "", latlon)
latlon<- gsub("[}]", "", latlon)
latlon<- gsub('\"', "", latlon, fixed = TRUE)
colnames(latlon) <- c("decimalLatitude", "decimalLongitude")
latlon <- as.data.frame(latlon)
idigbio <- cbind(idigbio, latlon)
```


## 3. idigbio- Standardize column names and select the ones we want

```{r}
idigbio <- idigbio %>% 
  dplyr::rename(dontwantdate = dwc.eventDate, source = dwc.institutionCode)
colnames <- gsub('dwc.', "", colnames(idigbio), fixed = TRUE)
colnames <- gsub('idigbio.', "", colnames, fixed = TRUE)
```
Assigned standardized colnames
```{r}
colnames(idigbio) = colnames
```

```{r}
idigbio <- idigbio %>% 
  dplyr::select(dplyr::any_of(Allfields))
idigbio
```



## 4. Collate herbarium data into a single dataframe

 Create empty dataframe with these columns
```{r}
combinedDF <-  setNames(data.frame(matrix(ncol = length(Allfields), nrow = 0)), Allfields)
```
```{r}
#creating the correct source data for each
BISH$source <- "BISH"
PTBG$source <- "PTBG"
US$source <- "US"
```
Combine

```{r}
combinedDF <- dplyr::bind_rows(mutate_all(combinedDF, as.character), mutate_all(BISH, as.character), mutate_all(PTBG, as.character), mutate_all(US, as.character), mutate_all(GBIF_pres_spec, as.character), mutate_all(idigbio, as.character))
```
```{r}
nrow(combinedDF)
```

## 5. Remove Duplicates
Removes obvious duplicates, BISH should be kept because it's the first in the dataframe
```{r}
#deduped_combinedDF <-distinct(combinedDF, locality, recordedBy, recordNumber, eventDate, scientificName, decimalLatitude, .keep_all = TRUE)
deduped_combinedDF <- combinedDF
```
```{r}
#How many duplicates did we remove?
nrow(combinedDF) - nrow(deduped_combinedDF)
```
assign UUID to make later merges easier
```{r}
deduped_combinedDF$UUID <- random_id(n = nrow(deduped_combinedDF), bytes = 16, use_openssl = TRUE)
```

## 6. Standardize the spelling of island names
Only care about the main islands for now

```{r}
#remove the term " island"
deduped_combinedDF$island <- gsub(" island", "", deduped_combinedDF$island)
deduped_combinedDF$island <- gsub(" Island", "", deduped_combinedDF$island)
#removing the punctuation
deduped_combinedDF$island <- gsub("`", "", deduped_combinedDF$island)
deduped_combinedDF$island <- gsub("'", "", deduped_combinedDF$island)
deduped_combinedDF$island <- gsub("&", "and", deduped_combinedDF$island)
# only first letter upper case
deduped_combinedDF$island <- str_to_title(deduped_combinedDF$island)
# deal with the unknown islands
deduped_combinedDF$island <- gsub('Sandwichs', "", deduped_combinedDF$island)
deduped_combinedDF$island <- gsub('Sand', "Oahu", deduped_combinedDF$island)
deduped_combinedDF$island <- gsub("Unknown", "" , deduped_combinedDF$island)
deduped_combinedDF$island <- gsub('Ouau [Oahu]', "Oahu" , deduped_combinedDF$island, fixed = TRUE)

```

```{r}
nrow(deduped_combinedDF)
```

## 7. Remove bad points by seeing which fall in the ocean.
```{r}
deduped_combinedDF$decimalLatitude <- dplyr::na_if(deduped_combinedDF$decimalLatitude, "")
deduped_combinedDF$decimalLongitude <- dplyr::na_if(deduped_combinedDF$decimalLongitude, "")

nocoords <- subset(deduped_combinedDF, is.na(decimalLatitude))
hascoords <- subset(deduped_combinedDF, !is.na(decimalLatitude))
```
How many have coordinates (no matter how bad)?
```{r}
nrow(hascoords)
```
```{r}
oo <- coord_incomplete(hascoords, lat = "decimalLatitude", lon = "decimalLongitude", drop = TRUE)
oo <- coord_imprecise (oo, which = "both", lat = "decimalLatitude", lon = "decimalLongitude", drop = TRUE)
oo <- coord_unlikely (oo, lat = "decimalLatitude", lon = "decimalLongitude", drop = TRUE)
oo$CleanCoordinates <- "yes"
oo <- oo %>% dplyr::select(UUID, CleanCoordinates)
hascoords <- merge(hascoords, oo, by="UUID", all.x = TRUE, all.y = FALSE)
```

```{r}
hascoords_sub <- subset(hascoords, CleanCoordinates == "yes")
hascoords_sub <- sf::st_as_sf(hascoords_sub, coords = c("decimalLongitude", "decimalLatitude"), crs = 4326)

hascoords_sub <- st_join(hascoords_sub, islandpolys, join = st_intersects,  left = TRUE )
```
```{r}
hascoords_sub_deoceanized <- subset(as.data.frame(hascoords_sub), !is.na(hascoords_sub$isle))
hascoords_sub_deoceanized$CleanCoordinates_not_ocean <- "yes"
hascoords_sub_deoceanized
```
replace island Nas with values from shapefile "isle" column
this is helpful for records that didn't record the island name, but have an accurate GPS point
```{r}
hascoords_sub_deoceanized$island <- hascoords_sub_deoceanized$isle
hascoords_sub_deoceanized$island <- gsub("kahoolawe", "Kahoolawe", hascoords_sub_deoceanized$island)
```

merge deoceanized column back into main dataframe
```{r}
# mergin back with orginal data.frame
ee <- hascoords_sub_deoceanized %>% dplyr::select(UUID, CleanCoordinates_not_ocean)
finalDF <- merge(deduped_combinedDF, ee, by="UUID", all.x = TRUE, all.y = FALSE)
```
replace lat lons with NAs if their point isn't clean and landing on land
```{r}
nicecoords <- subset(finalDF, CleanCoordinates_not_ocean == "yes")
notnicecoords <- subset(finalDF, is.na(CleanCoordinates_not_ocean))
notnicecoords$decimalLatitude <- NA
notnicecoords$decimalLongitude <- NA
#rbind back together
finalDF <- rbind(nicecoords,notnicecoords)
```

```{r}
nrow(finalDF)
```

## 8. Standardize Dates into Year-Month-Day format

A temporary work-around

```{r}
finalDF$eventDate <- gsub("T00:00:00", "", finalDF$eventDate)
finalDF$eventDate <- gsub("T.*", "", finalDF$eventDate)
finalDF$eventDate <- gsub("[+].*", "", finalDF$eventDate)
gooddate = "[[:digit:]]{4}-[[:digit:]]{2}-[[:digit:]]{2}"
correct_format <- grepl.sub(data = finalDF, pattern = gooddate, Var = "eventDate", keep.found = TRUE)
incorrect_format <- grepl.sub(data = finalDF, pattern = gooddate, Var = "eventDate", keep.found = FALSE)
```

```{r}
nrow(correct_format)
```


Just getting the year for the incorrect format

```{r}
incorrect_format$eventDate <- stri_extract_first_regex(incorrect_format$eventDate, "[[:digit:]]{4}")
incorrect_format$eventDate <- paste0(incorrect_format$eventDate, "-00-00")
incorrect_format$eventDate <- gsub("NA-00-00", "NA", incorrect_format$eventDate)
```
```{r}
#bind the reformatted dates back together

finalDF <- rbind(correct_format, incorrect_format)
```

```{r}
nrow(finalDF)
```

<!-- ```{r} -->
<!-- finalDF$year <- finalDF$eventDate -->
<!-- finalDF$year <- gsub("T00:00:00", "", finalDF$year) -->
<!-- finalDF$year <- gsub("0000", "", finalDF$year) -->
<!-- finalDF$year <- stri_extract_first_regex(finalDF$year, "[[:digit:]]{4}") -->
<!-- finalDF$year[finalDF$year >2020] <- NA -->
<!-- finalDF$year[finalDF$year <1790] <- NA -->
<!-- sort(unique(finalDF$year)) -->
<!-- ``` -->

<!-- THIS IS CURRENTLY REALLY ASSIGNING INNACCURATE DATES!! -->
<!-- Now the rest of the eventDatefield -->
<!-- ```{r} -->
<!-- # First, get weird of weird words (e.g. "Summer" is not helpful, we just want the year in this case) -->
<!-- finalDF$eventDate <- gsub("Winter", "", finalDF$eventDate) -->
<!-- finalDF$eventDate <- gsub("Summer", "", finalDF$eventDate) -->
<!-- finalDF$eventDate <- gsub("Spring", "", finalDF$eventDate) -->
<!-- finalDF$eventDate <- gsub("Late", "", finalDF$eventDate) -->
<!-- finalDF$eventDate <- gsub("ca", "", finalDF$eventDate) -->
<!-- finalDF$eventDate <- gsub("ca.", "", finalDF$eventDate) -->
<!-- finalDF$eventDate <- gsub("[.]", " ", finalDF$eventDate) -->
<!-- finalDF$eventDate <- gsub("[[?]]", "", finalDF$eventDate) -->
<!-- finalDF$eventDate <- gsub("T00:00:00", "", finalDF$eventDate) -->

<!-- # Second, we'll get rid of ranges by taking the first date mentioned (in all cases in the dataset,this only makes a few days of difference) -->
<!-- finalDF$eventDate <- gsub("to.*", "", finalDF$eventDate) -->
<!-- finalDF$eventDate <- gsub("or.*", "", finalDF$eventDate) -->
<!-- finalDF$eventDate <- gsub("[(].*", "", finalDF$eventDate) -->
<!-- finalDF$eventDate <- gsub("and.*", "", finalDF$eventDate) -->

<!-- #third, we'll trim the whitespaces off the end -->
<!-- finalDF$eventDate <- str_trim(finalDF$eventDate, side = "both") -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Fourth, we need to divide the dataset into different date formats so we can apply different treatments to get to the right format -->
<!-- # lets assign a column that looks at the number of characters -->
<!-- finalDF$nchar_temp <- nchar(finalDF$eventDate) -->
<!-- unique(finalDF$nchar_temp) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- #divide into different groups -->
<!-- justyear <- subset(finalDF, nchar_temp >= 0 & nchar_temp <= 7) -->
<!-- eightchars <- subset(finalDF, nchar_temp == 8) -->
<!-- ninepluschars <- subset(finalDF, nchar_temp >= 9) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #justyear -->
<!-- # remove any month only entries -->
<!-- regexp_alpha <- "[[:alpha:]]+" -->
<!-- regexp_symbols <- "[[:punct:][:blank:]]+" -->
<!-- justyear$eventDate <- gsub(regexp_alpha, "", justyear$eventDate) -->
<!-- justyear$eventDate <- gsub(regexp_symbols, "", justyear$eventDate) -->
<!-- # this will assume that anything that's two digits (e.g. "74") means 1974. but not for anything that can be confused with the 2000s. -->

<!-- # convert to format -->
<!-- justyear$eventDate <- lubridate::parse_date_time(justyear$eventDate, "%Y") -->
<!-- justyear$eventDate <- gsub( "-01-01", "-00-00", justyear$eventDate) -->
<!-- #done! -->
<!-- # we'll get a " many failed to parse" here, and that's okay cuz those strings were missing -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # fix eightchars -->
<!-- eightchars$eventDate <- lubridate::parse_date_time(eightchars$eventDate, "%m-%Y") -->
<!-- #since only month and year were assigned, we're going to assign a day of NA -->
<!-- eightchars$eventDate <- stringi::stri_replace_last_fixed(eightchars$eventDate, '-01 UTC', '-00') -->
<!-- #done! -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #fix nine-eleven chars -->
<!-- # gotta subset cuz there is two types here -->
<!-- regexp_alpha <- "[[:alpha:]]+" -->
<!-- ninepluschars_alpha <- grepl.sub(data = ninepluschars, pattern = regexp_alpha, Var = "eventDate", keep.found = TRUE) -->
<!-- ninepluschars_other <- grepl.sub(data = ninepluschars, pattern = regexp_alpha, Var = "eventDate", keep.found = FALSE) -->

<!-- ninepluschars_alpha$eventDate <- lubridate::dmy(ninepluschars_alpha$eventDate) -->

<!-- ninepluschars_other$eventDate <- lubridate::ymd(ninepluschars_other$eventDate) -->

<!-- ninepluschars <- rbind(ninepluschars_alpha, ninepluschars_other) -->

<!-- ``` -->

<!-- ```{r} -->
<!-- finalDF <- rbind(justyear, eightchars, ninepluschars) -->
<!-- ``` -->
### standardizing institution names
```{r}
finalDF$source <- gsub("Auckland War Memorial Museum", "AK", finalDF$source)
finalDF$source <- gsub("Arizona State University Biocollections", "ASU", finalDF$source)
finalDF$source <- gsub("Australia's Virtual Herbarium", "AVH", finalDF$source)
finalDF$source <- gsub("Australian Tropical Herbarium", "CNS", finalDF$source)
finalDF$source <- gsub("Bernice Pauahi Bishop Museum", "BISH", finalDF$source)
finalDF$source <- gsub("Biological Collections, California State University Northridge", "SFV", finalDF$source)
finalDF$source <- gsub("Boston University", "BSN", finalDF$source)
finalDF$source <- gsub("BPBM", "BISH", finalDF$source)
finalDF$source <- gsub("Botanic Garden and Botanical Museum Berlin", "B", finalDF$source)
finalDF$source <- gsub("Brown", "BRU", finalDF$source)
finalDF$source <- gsub("CalBG", "RSA", finalDF$source)
finalDF$source <- gsub("California Academy of Sciences", "CAS", finalDF$source)
finalDF$source <- gsub("California State University, Fullerton", "MACF", finalDF$source)
finalDF$source <- gsub("California State University, Long Beach", "LOB", finalDF$source)
finalDF$source <- gsub("Canadian Museum of Nature", "CAN", finalDF$source)
finalDF$source <- gsub("Centre for Australian National Biodiversity Research", "CBG", finalDF$source)
finalDF$source <- gsub("Carnegie Museums", "CM", finalDF$source)
finalDF$source <- gsub("Colgate University", "GRCH", finalDF$source)
finalDF$source <- gsub("Conservatoire et Jardin botaniques de la Ville de Gen?¿ve - G", "G", finalDF$source, fixed = TRUE)
finalDF$source <- gsub("CSU Los Angeles Herbarium", "LAM", finalDF$source)
finalDF$source <- gsub("Desert Botanical Garden Herbarium", "DES", finalDF$source)
finalDF$source <- gsub("Fairchild Tropical Botanic Garden", "FTG", finalDF$source)
finalDF$source <- gsub("Field Museum", "F", finalDF$source)
finalDF$source <- gsub("Harvard University Herbaria", "HUH", finalDF$source)
finalDF$source <- gsub("Instituto Agron??mico (IAC)", "IAC", finalDF$source, fixed = TRUE)
finalDF$source <- gsub("Instituto de Pesquisas Jardim Botanico do Rio de Janeiro", "RB", finalDF$source)
finalDF$source <- gsub("Kathryn Kalmbach Herbarium (Denver Botanic Gardens)", "KHD", finalDF$source, fixed = TRUE)
finalDF$source <- gsub("Instituto Nacional de Pesquisas da AmazÃ´nia (INPA)", "INPA", finalDF$source, fixed = TRUE)
finalDF$source <- gsub("Landcare Research", "CHR", finalDF$source)
finalDF$source <- gsub("Louisiana State University Herbarium", "LSU", finalDF$source)
finalDF$source <- gsub("Lund Botanical Museum (LD)", "LD", finalDF$source, fixed = TRUE)
finalDF$source <- gsub("Masaryk University, Department of Botany and Zoology", "BRNU", finalDF$source)
finalDF$source <- gsub("Michigan State University Herbarium", "MSC", finalDF$source)
finalDF$source <- gsub("Milwaukee Public Museum", "MIL", finalDF$source)
finalDF$source <- gsub("MNHN - Museum national d'Histoire naturelle", "MNHN", finalDF$source)
finalDF$source <- gsub("National Museum of Natural History, Smithsonian Institution", "US", finalDF$source)
finalDF$source <- gsub("Natural History Museum", "US", finalDF$source)
finalDF$source <- gsub("National Ecological Observatory Network", "NEON", finalDF$source)
finalDF$source <- gsub("Natural History Museum, Vienna - Herbarium W", "W", finalDF$source)
finalDF$source <- gsub("Naturalis Biodiversity Center", "L", finalDF$source)
finalDF$source <- gsub("Rancho Santa Ana Botanic Garden", "RSA", finalDF$source)
finalDF$source <- gsub("Royal Botanic Garden Edinburgh", "E", finalDF$source)

finalDF$source <- gsub("Weber State University", "WSCO", finalDF$source)
finalDF$source <- gsub("Utah State University", "UTC", finalDF$source)
finalDF$source <- gsub("US, Vienna - Herbarium W", "W", finalDF$source)
finalDF$source <- gsub("University of Vienna - Herbarium WU", "W", finalDF$source)
finalDF$source <- gsub("University of Texas at Austin, Biodiversity Collections", "TEX", finalDF$source)
finalDF$source <- gsub("University of Texas at El Paso Biodiversity Collections", "UTEP", finalDF$source)
finalDF$source <- gsub("University of Tennessee Herbarium", "TENN", finalDF$source)
finalDF$source <- gsub("University of South Carolina", "USCH", finalDF$source)
finalDF$source <- gsub("University of Rhode Island", "KIRI", finalDF$source)
finalDF$source <- gsub("University of North Carolina at Chapel Hill Herbarium (NCU)", "NCU", finalDF$source, fixed = TRUE)
finalDF$source <- gsub("University of New England", "NE", finalDF$source)
finalDF$source <- gsub("University of Minnesota Bell Museum", "MIN", finalDF$source)
finalDF$source <- gsub("University of Michigan Herbarium", "MICH", finalDF$source)
finalDF$source <- gsub("University of Kansas Biodiversity Institute", "KANU", finalDF$source)
finalDF$source <- gsub("University of Graz, Institute of Plant Sciences", "GZU", finalDF$source)
finalDF$source <- gsub("University of Connecticut", "CONN", finalDF$source)
finalDF$source <- gsub("University of California, Davis", "DAV", finalDF$source)
finalDF$source <- gsub("University of California Riverside", "UCR", finalDF$source)
finalDF$source <- gsub("University of Calgary Herbarium", "UAC", finalDF$source)
finalDF$source <- gsub("University of Calgary", "UAC", finalDF$source)
finalDF$source <- gsub("University of British Columbia", "UBC", finalDF$source)
finalDF$source <- gsub("University of Alberta Museums", "ALTA", finalDF$source)
finalDF$source <- gsub("University of Alabama Biodiversity and Systematics", "UNA", finalDF$source)
finalDF$source <- gsub("Universit?? de Montr??al Biodiversity Centre", "LT", finalDF$source, fixed = TRUE)
finalDF$source <- gsub("Universidade Federal da Bahia", "ALCB", finalDF$source)
finalDF$source <- gsub("Universidade Estadual Paulista - IBB", "HISA", finalDF$source)
finalDF$source <- gsub("Universidade Estadual de Londrina", "FUEL", finalDF$source)
finalDF$source <- gsub("Universidade de S?úo Paulo", "ESA", finalDF$source, fixed = TRUE)
finalDF$source <- gsub("Universidad Nacional de Colombia", "COL", finalDF$source)
finalDF$source <- gsub("The University of Vermont Pringle Herbarium", "VT", finalDF$source)
finalDF$source <- gsub("The University of Melbourne", "MELU", finalDF$source)
finalDF$source <- gsub("The Royal Botanic Gardens & Domain Trust", "NSW", finalDF$source)
finalDF$source <- gsub("Tasmanian Museum and Art Gallery", "HO", finalDF$source)
finalDF$source <- gsub("Taiwan Forestry Research Institute", "TAIF", finalDF$source)
finalDF$source <- gsub("Staatliche Naturwissenschaftliche Sammlungen Bayerns", "M", finalDF$source)
finalDF$source <- gsub("South African National Biodiversity Institute", "NBG", finalDF$source)
finalDF$source <- gsub("San Jose State University", "SJSU", finalDF$source)
finalDF$source <- gsub("San Diego US", "SDSU", finalDF$source)
finalDF$source <- gsub("San Diego State University Herbarium (SDSU)", "code", finalDF$source, fixed = TRUE)
finalDF$source <- gsub("Rutger's University - Chrysler Herbarium", "CHRB", finalDF$source)
finalDF$source <- gsub("The New York Botanical Garden", "NY", finalDF$source)
finalDF$source <- gsub("United Herbaria of the University and ETH Zurich (Z+ZT)", "Z", finalDF$source)
finalDF$source <- gsub("Royal Botanic Gardens, Kew", "K", finalDF$source)
```



## assigning duplicates

```{r}
temp <- finalDF %>% find_duplicates(locality, recordedBy, recordNumber, eventDate, scientificName, habitat)
temp$isDuplicate <- "Yes"
temp <- temp %>% dplyr::select(UUID, isDuplicate)
```
```{r}
finalDF <- merge(finalDF, temp, by = "UUID", all.x = TRUE, all.y = FALSE)
```

```{r}
nrow(finalDF)
```

## 9. Assign a cultivated, non,  or unknown status


```{r}
finalDF$isCultivated <- gsub("[?]", "", finalDF$isCultivated)

finalDF$isCultivated <- gsub(-1, NA, finalDF$isCultivated)
finalDF$isCultivated <- gsub(0, NA, finalDF$isCultivated)
finalDF$isCultivated <- gsub(1, "Cultivated", finalDF$isCultivated)
finalDF$isCultivated <- gsub("Yes", "Cultivated", finalDF$isCultivated)
finalDF$isCultivated <- gsub("TRUE", "Cultivated", finalDF$isCultivated)
finalDF$isCultivated <- gsub("FALSE", NA, finalDF$isCultivated)
finalDF$isCultivated[finalDF$isCultivated == ""] <- NA
```

```{r}
finalDF_cult <- subset(finalDF, !is.na(finalDF$isCultivated))
finalDF_nocult <- subset(finalDF, is.na(finalDF$isCultivated))
```

```{r}
nrow(finalDF_cult) + nrow(finalDF_nocult) 
```

```{r}
#look for "cultivat"

finalDF_nocult$cultivate <- ifelse(grepl("cultivat", finalDF_nocult$habitat, ignore.case = TRUE) | 
                           grepl("cultivat", finalDF_nocult$occurrenceRemarks, ignore.case = TRUE) |
                           grepl("cultivat", finalDF_nocult$associatedTaxa, ignore.case = TRUE) |
                           grepl("cultivat", finalDF_nocult$locality, ignore.case = TRUE) , "Cultivated", NA)

```

```{r}
#look for "naturalize"

finalDF_nocult$naturalize <- ifelse(grepl("naturalize", finalDF_nocult$habitat, ignore.case = TRUE) | 
                           grepl("naturalize", finalDF_nocult$occurrenceRemarks, ignore.case = TRUE) |
                           grepl("naturalize", finalDF_nocult$associatedTaxa, ignore.case = TRUE) |
                           grepl("naturalize", finalDF_nocult$locality, ignore.case = TRUE) , "Not Cultivated", NA)
```

```{r}
#look for "escape"

finalDF_nocult$escape <- ifelse(grepl("escape", finalDF_nocult$habitat, ignore.case = TRUE) | 
                           grepl("escape", finalDF_nocult$occurrenceRemarks, ignore.case = TRUE) |
                           grepl("escape", finalDF_nocult$associatedTaxa, ignore.case = TRUE) |
                           grepl("escape", finalDF_nocult$locality, ignore.case = TRUE) , "Not Cultivated", NA)

```

```{r}
#look for "adventiv"

finalDF_nocult$adventive <- ifelse(grepl("adventiv", finalDF_nocult$habitat, ignore.case = TRUE) | 
                           grepl("adventiv", finalDF_nocult$occurrenceRemarks, ignore.case = TRUE) |
                           grepl("adventiv", finalDF_nocult$associatedTaxa, ignore.case = TRUE) |
                           grepl("adventiv", finalDF_nocult$locality, ignore.case = TRUE) , "Not Cultivated", NA)

```

```{r}
#colalescing the columns

finalDF_nocult$isCultivated <- dplyr::coalesce(finalDF_nocult$naturalize, finalDF_nocult$escape, finalDF_nocult$adventive, finalDF_nocult$cultivate)

```

```{r}
#merge data back together

allplusdups <- c(Allfields, "isDuplicate")

finalDF_nocult <- finalDF_nocult %>% dplyr::select(all_of(allplusdups))
finalDF_cult <- finalDF_cult %>% dplyr::select(all_of(allplusdups))
finalDF <- rbind(finalDF_cult, finalDF_nocult)
```
```{r}
nrow(finalDF)
```



## More duplicate work
```{r}
#temporarily making BISH #1
finalDF$source <- gsub("BISH", "01BISH", finalDF$source)
finalDF$source[finalDF$source==""]<-NA
```
```{r}
#making sure BISH specimens are first
finalDF <- dplyr::arrange(finalDF, source)
```

```{r}
comb <- with(finalDF, paste(locality, recordedBy, recordNumber, eventDate, habitat))
finalDF <- within(finalDF, Dup_Group <- match(comb, unique(comb)))
finalDF
```

```{r}
length(unique(finalDF$Dup_Group))
```


making a unique location ID
```{r}
first <- random_id(n = length(unique(finalDF$Dup_Group)), bytes = 8, use_openssl = TRUE)
second <- random_id(n = length(unique(finalDF$Dup_Group)), bytes = 4, use_openssl = TRUE)
third <- random_id(n = length(unique(finalDF$Dup_Group)), bytes = 3, use_openssl = TRUE)
fourth <- random_id(n = length(unique(finalDF$Dup_Group)), bytes = 4, use_openssl = TRUE)
fifth <- random_id(n = length(unique(finalDF$Dup_Group)), bytes = 12, use_openssl = TRUE)
locationiddf <- as.data.frame(cbind(first, second, third, fourth, fifth))
locationID <- paste0(locationiddf$first, "-" ,locationiddf$second, "-", 4, locationiddf$third, "-", locationiddf$fourth, "-", locationiddf$fifth)   
head(locationID, 25)
```
```{r}
locDF <- as.data.frame(cbind((order(unique(finalDF$Dup_Group))), locationID))
locDF
```

```{r}
finalDF <- finalDF %>% dplyr:: select(-c(occurrenceID, locationID))
```
```{r}
finalDF <- merge(finalDF, locDF, by.x = "Dup_Group", by.y = "V1", all.x = TRUE)
finalDF
```

##### occurrence ID making... 
```{r}
#making sure BISH specimens are first
finalDF <- dplyr::arrange(finalDF, source)
```
```{r}
first <- random_id(n = length(unique(finalDF$Dup_Group)), bytes = 8, use_openssl = TRUE)
second <- random_id(n = length(unique(finalDF$Dup_Group)), bytes = 4, use_openssl = TRUE)
third <- random_id(n = length(unique(finalDF$Dup_Group)), bytes = 3, use_openssl = TRUE)
fourth <- random_id(n = length(unique(finalDF$Dup_Group)), bytes = 4, use_openssl = TRUE)
fifth <- random_id(n = length(unique(finalDF$Dup_Group)), bytes = 12, use_openssl = TRUE)
occurrenceiddf <- as.data.frame(cbind(first, second, third, fourth, fifth))
occurrenceID <- paste0(occurrenceiddf$first, "-" ,occurrenceiddf$second, "-", 4, occurrenceiddf$third, "-", occurrenceiddf$fourth, "-", occurrenceiddf$fifth)   
head(occurrenceID, 25)
```
```{r}
occDF <- as.data.frame(cbind((order(unique(finalDF$Dup_Group))), occurrenceID))
occDF
```

```{r}
finalDF <- merge(finalDF, occDF, by.x = "Dup_Group", by.y = "V1", all.x = TRUE)
finalDF
```


```{r}
#rename BISH #1
finalDF$source <- gsub( "01BISH", "BISH", finalDF$source)
```


Indicating the Basis of Record

```{r}
finalDF$basisOfRecord <- "Preserved_Specimen"
```


```{r}
finalDF <-distinct(finalDF, occurrenceID, source, .keep_all = TRUE)
finalDF
```


```{r}
#forwrite <- gsub("\t", "", finalDF)
write.csv(finalDF, file = "All_herbaria_COMPILED_2021-06-29.csv", row.names = FALSE)
saveRDS(finalDF, file= "All_herbaria_COMPILED_2021-06-29.rds")
```

```{r}
Taxonfields <- c( "taxonID", "acceptedNameUsageID", "IPNIID", "parentNameUsageID", "scientificName", "scientificNameAuthorship", "namePublishedIn", "originalNameUsage", "taxonRank", "kingdom", "phylum", "class", "order", "family", "genus", "subgenus", "specificEpithet", "vernacularName", "taxonRemarks")

Locationfields <- c("locationID", "higherGeographyID", "locationType", "continent", "waterbody", "islandGroup", "island", "country", "countrycode", "stateProvince", "county", "municipality", "locality", "minimumElevationInMeters", "maximumElevationInMeters", "decimalLatitude", "decimalLongitude", "geodeticDatum", "coordinateUncertaintyInMeters", "footprintWKT", "footprintSRS", "locationRemarks" )

Occurrencefields <- c("occurrenceID", "taxonID", "locationID", "basisOfRecord", "catalogNumber", "recordNumber", "recordedBy", "individualCount", "organismQuantity", "organismQuantityType", "identifiedby", "identificationVerification", "sex", "lifeStage", "reproductiveCondition", "behavior", "establishmentMeans", "occurrenceStatus", "preparations", "disposition", "associatedMedia", "associatedReferences", "associatedTaxa", "otherCatalogNumbers", "occurrenceRemarks", "fieldNumber", "eventDate", "eventTime", "habitat", "samplingProtocol", "fieldNotes", "watershedCount", "isCultivated", "source", "sourceIdentifier", "sourceURL")

forPOH <- c("occurrenceID",	"taxonID",	"acceptedNameUsageID",	"locationID",	"basisOfRecord",	"catalogNumber",	'recordNumber',	'recordedBy',	'individualCount', 'identifiedby',"establishmentMeans",	'occurrenceStatus',	'disposition',	'associatedMedia',	'associatedTaxa',	'otherCatalogNumbers',	'occurrenceRemarks',	'eventDate',	'habitat',	'samplingProtocol',	'fieldNotes',	'isCultivated',	'source',	'sourceIdentifier',	'island',	'locality',	'minimumElevationInMeters',	'maximumElevationInMeters',	'decimalLatitude',	'decimalLongitude',	'coordinateUncertaintyInMeters')
length(forPOH)
```


Separating the occurrence and location
```{r}
OccurrenceDF <- finalDF %>% dplyr::select(all_of(Occurrencefields))
LocationDF <- finalDF %>% dplyr::select(all_of(Locationfields))
forPOH <- finalDF %>% dplyr::select(all_of(forPOH))
```


```{r}
#forwrite <- gsub("\t", "", finalDF)
write.csv(OccurrenceDF, file = "Occurrence_COMPILED_2021-06-29.csv", row.names = FALSE)
write.csv(LocationDF, file= "Location_COMPILED_2021-06-29.csv", row.names = FALSE)
write.csv(forPOH, file= "herb_forPOH_2021-06-29.csv", row.names = FALSE)
```



